import streamlit as st
import openai
import pandas as pd
from datetime import datetime
import base64
from langchain.llms import OpenAI
from openai import OpenAI


# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="AI Chatbot Tuning Studio"
                    ,page_icon=":mage:"
                   ,layout="wide")


# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
def initialize_session_state():
    if 'api_key' not in st.session_state:
        st.session_state.api_key = ''
    if 'llm_model' not in st.session_state:
        st.session_state.llm_model = 'gpt-4'
    if 'instructions' not in st.session_state:
        st.session_state.instructions = '''
    ë‹¹ì‹ ì€ ì•„ë˜ ìì‚¬ í™”ì¥í’ˆ ì œí’ˆì„ ì†Œê°œí•˜ëŠ” AI ì±—ë´‡ì…ë‹ˆë‹¤. 
    ìì‚¬ì œí’ˆì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

1. ë§ˆìŠ¤í¬íŒ©
- íŠ¹ì„±:ê³ ë†ì¶• ì—ì„¼ìŠ¤ê°€ í•¨ìœ ëœ ì‹œíŠ¸í˜• ë§ˆìŠ¤í¬íŒ©ìœ¼ë¡œ í”¼ë¶€ì— ê¹Šì€ ë³´ìŠµê³¼ ì˜ì–‘ì„ ì œê³µí•©ë‹ˆë‹¤.
- ì„±ë¶„:
íˆì•Œë£¨ë¡ ì‚°(ê°•ë ¥í•œ ë³´ìŠµ íš¨ê³¼), ì•Œë¡œì— ë² ë¼ ì¶”ì¶œë¬¼(í”¼ë¶€ ì§„ì • ë° ë³´í˜¸)
- ì‚¬ìš© ë°©ë²•:
ì„¸ì•ˆ í›„ ë§ˆìŠ¤í¬íŒ©ì„ ì–¼êµ´ì— ë¶€ì°©í•˜ê³  15-20ë¶„ í›„ ì œê±°í•©ë‹ˆë‹¤. ë‚¨ì€ ì—ì„¼ìŠ¤ë¥¼ ê°€ë³ê²Œ ë‘ë“œë ¤ í¡ìˆ˜ì‹œì¼œì£¼ì„¸ìš”.
- íš¨ê³¼:
ì¦‰ê°ì ì¸ ìˆ˜ë¶„ ê³µê¸‰ê³¼ í”¼ë¶€ ì§„ì • íš¨ê³¼ë¡œ ì´‰ì´‰í•˜ê³  ìƒê¸° ìˆëŠ” í”¼ë¶€ë¥¼ ìœ ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

2. ì„ ì¿ ì…˜
- íŠ¹ì„±: íœ´ëŒ€ê°€ ê°„í¸í•œ ì¿ ì…˜ íƒ€ì… ìì™¸ì„  ì°¨ë‹¨ì œë¡œ SPF50+ PA+++ì˜ ê°•ë ¥í•œ ìì™¸ì„  ì°¨ë‹¨ íš¨ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
- ì„±ë¶„:
í‹°íƒ€ëŠ„ ë””ì˜¥ì‚¬ì´ë“œ(ìì™¸ì„  ì°¨ë‹¨), ì•Œë¡œì— ì¶”ì¶œë¬¼(í”¼ë¶€ ì§„ì •)
- ì‚¬ìš© ë°©ë²•:
ì™¸ì¶œ ì „ í¼í”„ì— ì ë‹¹ëŸ‰ì„ ëœì–´ ì–¼êµ´ê³¼ ëª©ì— ê³ ë¥´ê²Œ ë°œë¼ì¤ë‹ˆë‹¤. í•„ìš”ì‹œ ìˆ˜ì‹œë¡œ ë§ë°œë¼ì£¼ì„¸ìš”.
- íš¨ê³¼:
ê°•ë ¥í•œ ìì™¸ì„  ì°¨ë‹¨ìœ¼ë¡œ í”¼ë¶€ë¥¼ ë³´í˜¸í•˜ê³ , ì´‰ì´‰í•œ ì‚¬ìš©ê°ìœ¼ë¡œ í•˜ë£¨ ì¢…ì¼ í¸ì•ˆí•œ í”¼ë¶€ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.

3. ì˜ì–‘í¬ë¦¼
- íŠ¹ì„±:
í’ë¶€í•œ ì˜ì–‘ ì„±ë¶„ì´ í•¨ìœ ëœ ê³ ë³´ìŠµ í¬ë¦¼ìœ¼ë¡œ í”¼ë¶€ì— ê¹Šì€ ì˜ì–‘ê³¼ íƒ„ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
- ì„±ë¶„:
ì‰ì–´ë²„í„°(ê¹Šì€ ë³´ìŠµê³¼ ì˜ì–‘ ê³µê¸‰), ë¹„íƒ€ë¯¼ E(í•­ì‚°í™” íš¨ê³¼)
- ì‚¬ìš© ë°©ë²•:
ì•„ì¹¨ê³¼ ì €ë…, ì„¸ì•ˆ í›„ ì ë‹¹ëŸ‰ì„ ëœì–´ ì–¼êµ´ê³¼ ëª©ì— ë¶€ë“œëŸ½ê²Œ í´ ë°œë¼ì¤ë‹ˆë‹¤.
- íš¨ê³¼:
ì§€ì†ì ì¸ ë³´ìŠµê³¼ ì˜ì–‘ ê³µê¸‰ìœ¼ë¡œ í”¼ë¶€ë¥¼ íƒ„ë ¥ ìˆê³  ê±´ê°•í•˜ê²Œ ìœ ì§€í•©ë‹ˆë‹¤.
        '''
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    if 'temperature' not in st.session_state:
        st.session_state.temperature = 0.7
    if 'max_tokens' not in st.session_state:
        st.session_state.max_tokens = 150
    if 'top_p' not in st.session_state:
        st.session_state.top_p = 1.0
    if 'feedback' not in st.session_state:
        st.session_state.feedback = ''
    if "messages" not in st.session_state:
        st.session_state.messages = []

initialize_session_state()


#################################################################
# ì‚¬ì´ë“œë°” ì„¤ì •
st.sidebar.title("ğŸ““Your Recipe")
st.sidebar.subheader("LLM Selection")
# sidebar : ëª¨ë¸ ì„ íƒ
llm_model = st.sidebar.selectbox("Choose your LLM", ('gpt-3.5-turbo', 'gpt-4o', 'llama2', 'gemini'), index=0)
if 'gpt' not in llm_model:
    st.sidebar.warning('gpt ì™¸ ëª¨ë¸ì€ í˜„ì¬ ì—…ë°ì´íŠ¸ ì¤‘ì…ë‹ˆë‹¤. gpt ëª¨ë¸ë§Œ ì„ íƒí•˜ì„¸ìš”.')
# sidebar : API Key
api_key = st.sidebar.text_input("Enter API Key", type="password",value=st.session_state.api_key)
# sidebar : prompt
instructions = st.sidebar.text_area("Instructions", value=st.session_state.instructions)

# sidebar : model parameters
st.sidebar.subheader("Response Settings")
temperature = st.sidebar.slider("Temperature", 0.0, 1.0, st.session_state.temperature)
max_tokens = st.sidebar.number_input("Max Tokens", 1, 1000, st.session_state.max_tokens)
top_p = st.sidebar.slider("Top P", 0.0, 1.0, st.session_state.top_p)

# todo : RAG ê´€ë ¨ parameter ì¶”ê°€
# chunking size, context window ë“±

# # sidebar : RAGì— ì“°ì¼ íŒŒì¼ ë°ì´í„° ì—…ë¡œë“œ
# rag_on = st.sidebar.toggle('Your data')
# if rag_on:
#     uploaded_file = st.sidebar.file_uploader("Upload a document for reference", type=['txt', 'pdf', 'docx'])
#     # todo : vector db ìƒì„±, ì¼ë‹¨ ìƒì„±ëœ vector dbëŠ” local ì €ì¥

# sidebar :
if st.sidebar.button("Save Settings"):
    st.session_state.api_key = api_key
    st.session_state.llm_model = llm_model
    st.session_state.instructions = instructions
    st.session_state.temperature = temperature
    st.session_state.max_tokens = max_tokens
    st.session_state.top_p = top_p

# sidebar : download your custom setting on your local.
@st.cache_data
def convert_df(df):
    # IMPORTANT: Cache the conversion to prevent computation on every rerun
    return df.to_csv().encode("utf-8")

dict_setting = [{'model': llm_model
                ,'instruction': instructions
                ,'temperature': temperature
                ,'max_tokens': max_tokens
                ,'top_p': top_p}]
df_setting = pd.DataFrame(dict_setting)
csvfile = convert_df(df_setting)
yyyymmdd = datetime.today().strftime("%Y%m%d")
# csv_file = df_setting.to_csv(f'AI_Chat_Settings_{yyyymmdd}.csv', index=False)

st.sidebar.download_button(
   "Download your custom",
   csvfile,
   f'AI_Chat_Settings_{yyyymmdd}.csv',
   "text/csv",
   key='download-csv'
)



#################################################################
# Main í™”ë©´ ì„¤ì •
st.title(":mage: AI Chatbot Tuning Studio")
st.subheader("Chat with your Customized AI")

# chat version 1
# user_input = st.text_input("Your message to the AI:")

# if st.button("Reset Chat"):
#     st.session_state.chat_history = []

# if st.button("Send"):
#     if user_input:
#         response = openai.ChatCompletion.create(
#             model=st.session_state.llm_model,
#             messages=[{"role": "system", "content": st.session_state.instructions},
#                       {"role": "user", "content": user_input}],
#             temperature=st.session_state.temperature,
#             max_tokens=st.session_state.max_tokens,
#             top_p=st.session_state.top_p,
#             api_key=st.session_state.api_key
#         )
#         response_message = response.choices[0].message['content']
#         st.session_state.chat_history.append((user_input, response_message))
#         st.write(f"AI: {response_message}")

if api_key == '':
    st.error('Please enter your API key')

else:
    # openai initialization
    # openai.api_key = api_key
    client = OpenAI(api_key = api_key)
    # chat version 2
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("ëˆ„êµ¬ì„¸ìš”"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            # Simulate stream of response with milliseconds delay

            # sidebarì˜ ì„¤ì •ê°’(model, instruction, temperature, top_p ë“±) 
            for response in client.chat.completions.create(
            # for response in openai.ChatCompletion.create(
                    model=st.session_state["llm_model"],
                    messages=[
                        {"role": m["role"], "content": m["content"]} for m in st.session_state.messages
                    ] + [{"role": "system","content": st.session_state.instructions}],
                    temperature=st.session_state.temperature,
                    top_p=st.session_state.top_p,
                    # will provide lively writing
                    stream=True,
            ):
                # get content in response
                # full_response += response.choices[0].delta.get("content", "")
                # full_response += response.choices[0].delta.content
                for choice in response.choices:
                    content = choice.delta.content
                    if content:
                        full_response += content
                        message_placeholder.markdown(full_response + "â–Œ")

                # Add a blinking cursor to simulate typing
                # message_placeholder.markdown(full_response + "â–Œ")

                # todo: ì§ˆë¬¸ê³¼ ë‹µë³€, í† í°ìˆ˜ë¥¼ ì¶”ì¶œí•´ì„œ Historyë¡œ ì €ì¥ê°€ëŠ¥í• ë“¯
                # https://platform.openai.com/docs/api-reference/chat/create
            message_placeholder.markdown(full_response)
        # Add assistant response to chat history
        st.session_state.messages.append({"role": "assistant", "content": full_response})


# ì±„íŒ… ë‚´ì—­ ë° í”¼ë“œë°± ì €ì¥ ê¸°ëŠ¥
# # í”¼ë“œë°± ì…ë ¥
# feedback = st.text_area("Enter your feedback on the conversation:")
# # CSV íŒŒì¼ ìƒì„± ë° ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥
# def create_csv_file():
#     df = pd.DataFrame(st.session_state.chat_history, columns=['User', 'AI'])
#     if df.empty:
#         df = pd.DataFrame([["No conversation yet", "No conversation yet"]], columns=['User', 'AI'])
#     df['Feedback'] = feedback
#     df['Model'] = st.session_state.llm_model
#     df['Temperature'] = st.session_state.temperature
#     df['Max Tokens'] = st.session_state.max_tokens
#     df['Top P'] = st.session_state.top_p
#     return df.to_csv(index=False).encode('utf-8')
#
# csv_file = create_csv_file()
# timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
# btn = st.download_button(
#     label="Download Chat History and Feedback",
#     data=csv_file,
#     file_name=f"chat_history_{timestamp}.csv",
#     mime="text/csv"
# )
#
# if st.session_state.chat_history:
#     st.write("Chat History:")
#     for user_msg, ai_msg in st.session_state.chat_history:
#         st.write(f"You: {user_msg}")
#         st.write(f"AI: {ai_msg}")
